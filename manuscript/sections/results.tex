\section{Results}

Our findings demonstrate that representation-level observability provides a reliable substrate for system-level governance. We present evidence across synthetic, vision, and biological domains.

\subsection{Detection and Observability}
The RLCS sensors successfully convert latent perturbations into observable signals. As shown in \textbf{Figure \ref{fig:stress_obs}}, both ResLik and TCS sensors track latent drift with high monotonicity. The ResLik score provides an early-warning signal, crossing the $\tau_D=3.0$ safety threshold well before the representation is completely corrupted. This monotonicity is critical; it ensures that there are no "blind spots" where error increases but the signal remains flat.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{figures/figure1_stress_observability.png}
    \caption{RLCS Sensor Observability. ResLik and TCS scores track latent drift, triggering ABSTAIN and DEFER signals respectively.}
    \label{fig:stress_obs}
\end{figure*}

\subsection{Efficacy of Gated Decoding}
\textbf{Figure \ref{fig:on_off}} contrasts the behavior of the governed (\textit{resED ON}) and ungoverned (\textit{resED OFF}) systems. During a sudden shock event:
\begin{itemize}
    \item The \textbf{Ungoverned System (Grey)} continues to decode the corrupted latent, resulting in a high-variance, hallucinatory output. This illustrates the danger of "blind" decoding.
    \item The \textbf{Governed System (Green)} immediately transitions to \texttt{ABSTAIN}, suppressing the output ($y=\varnothing$, visualized as 0 norm) for the duration of the shock.
\end{itemize}
This result confirms that reliability is a function of the control surface, not the decoder's robustness. The system successfully prioritized safety over continuity.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{figures/figure2_resed_on_off.png}
    \caption{System Response. Governance prevents hallucination by suppressing output during shock events.}
    \label{fig:on_off}
\end{figure*}

\subsection{Dimensionality Scaling and Calibration}
A key finding is the impact of dimensionality on uncalibrated distance metrics. As shown in \textbf{Table \ref{tab:gov_outcomes}}, raw distance thresholds tuned for synthetic data (64D) failed catastrophically on high-dimensional benchmarks, rejecting 100\% of valid data for Vision (2048D) and Biology (128D) due to the curse of dimensionality ($\mathbb{E}[\|z\|] \propto \sqrt{d}$). 

The Reference-Conditioned Calibration Layer effectively neutralized this scaling factor. By mapping raw distances to a reference-relative Z-score, the clean acceptance rate was restored to >99\% across all domains, without manual threshold retuning.

\begin{table*}[t!]
\centering
\caption{Governance Outcomes Across Domains (Acceptance Rate \%)}
\label{tab:gov_outcomes}
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{Synthetic (64D)} & \textbf{Vision (2048D)} & \textbf{Biology (128D)} \\
\midrule
Clean (Uncalibrated) & 99.8\% & 0.0\%* & 0.0\%* \\
Clean (Calibrated)   & 99.8\% & 99.7\% & 99.6\% \\
Noise ($\sigma=0.6$) & 0.0\%  & 0.0\%  & 0.0\% \\
Shock (5\%)          & 95.0\% & 95.0\% & 95.0\% \\
\bottomrule
\end{tabular}
\par\smallskip
{\footnotesize *Rejection due to dimensionality scaling mismatch.}
\end{table*}

\begin{figure*}[t!]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/figure4a_bioteque_calibrated_sensor_response.pdf}
        \\ (a) Calibrated Sensor Response
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/figure4b_bioteque_calibrated_control_distribution.pdf}
        \\ (b) Control Distribution
    \end{minipage}
    \caption{Biological Validation. Calibration restores utility on high-dimensional data without compromising safety.}
    \label{fig:bio_calib}
\end{figure*}

\subsection{Analysis of Governance States}
While \texttt{ABSTAIN} handles catastrophic failure, the intermediate \texttt{DOWNWEIGHT} state ($3.0 < \hat{D} \le 4.0$) was observed during the onset of gradual drift. In this regime, the system continued to provide output but with reduced amplitude, effectively signaling "marginal confidence" to the user. This graded response prevents binary flickering between trust and distrust.

\subsection{Empirical Failure Envelopes}
Component stress testing revealed the intrinsic limits of the modules. As summarized in \textbf{Table \ref{tab:failure_envelopes}}, all components lack internal stability mechanisms. The encoder amplifies input noise linearly. The transformer, often assumed to be robust, suffers from a catastrophic "attention collapse" under heavy corruption.

\begin{table}[t!]
\centering
\caption{Summary of Component Failure Envelopes}
\label{tab:failure_envelopes}
\begin{tabular}{lll}
\toprule
\textbf{Component} & \textbf{Observed Failure Mode} & \textbf{Impact on Output} \\
\midrule
resENC & Variance Inflation & Radial Drift \\
resTR  & Attention Collapse & Noise Fixation \\
resDEC & Linear Error Prop. & Hallucination \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\columnwidth]{figures/figure_component_resenc_stability.pdf}
    \caption{Encoder Stability. Latent distortion scales linearly with input noise.}
    \label{fig:enc_stab}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\columnwidth]{figures/figure_component_restr_sensitivity.pdf}
    \caption{Transformer Sensitivity. Attention entropy collapses under heavy corruption.}
    \label{fig:tr_sens}
\end{figure}
