\section{Methodology}

The core innovation of the resED framework is the Representation-Level Control Surface (RLCS), a deterministic mechanism for governing the behavior of opaque generative models. This section details the mathematical foundations of the RLCS sensors, the calibration logic, and the control policy.

\subsection{Representation-Level Control Surface (RLCS)}
The RLCS operates on the principle of "Trust but Verify." It does not attempt to interpret the semantic content of a latent vector but instead evaluates its statistical consistency with a known "trust manifold." This manifold is defined by the empirical distribution of valid representations from a reference population $\mathcal{P}_{ref}$.

\subsubsection{Population Consistency (ResLik)}
The ResLik sensor measures the Mahalanobis-like distance of a new representation $z$ from the historical centroid of the reference population. To ensure scalability, we approximate this using a standardized Euclidean distance:
\begin{equation}
D(z) = \frac{\|z - \mu\|_2}{\sigma + \epsilon}
\end{equation}
where $\mu = \mathbb{E}[z]$ and $\sigma = \sqrt{\mathbb{V}[z]}$ are parameters estimated from $\mathcal{P}_{ref}$. A high $D(z)$ indicates a statistical anomaly, or "Stranger," suggesting the input lies outside the valid operational envelope of the encoder. Unlike classifier logits, which can be overconfident far from the decision boundary, this distance metric is monotonic and unbounded, preserving the magnitude of the anomaly.

\subsubsection{Temporal Consistency Sensor (TCS)}
For sequential data, the system enforces trajectory smoothness. The TCS monitors the rate of change in the latent space:
\begin{equation}
T(z_t, z_{t-1}) = \exp(-\|z_t - z_{t-1}\|_2)
\end{equation}
A sudden collapse in $T$ indicates a "Jitter" failureâ€”an unphysical discontinuity in the latent trajectory that often precedes semantic collapse.

\subsubsection{Multi-View Agreement Sensor (MVA)}
To further robustify the governance against subtle corruptions, we introduce the Multi-View Agreement sensor. This sensor enforces the invariant that valid representations should be invariant to semantics-preserving transformations of the input. For an input $x$ and a set of augmentations $\mathcal{T}$, MVA measures the divergence:
\begin{equation}
A(z) = \frac{1}{|\mathcal{T}|} \sum_{t \in \mathcal{T}} \|z - E(t(x))\|_2
\end{equation}
High divergence suggests that the encoder is unstable or that the input lies near a decision boundary cliff, warranting caution (e.g., \texttt{DOWNWEIGHT}).

\subsection{Reference-Conditioned Calibration}
A critical requirement for system-level reliability is the ability to define thresholds that generalize across domains. In high-dimensional spaces, the expected Euclidean distance scales with $\sqrt{d}$, making raw distance thresholds domain-specific and brittle.

To resolve this, we introduce a \textbf{Reference-Conditioned Calibration Layer}. This layer transforms raw diagnostic scores $D_{raw}$ into a universal risk coordinate (Z-score) using empirical quantile matching against the reference set:
\begin{equation}
\hat{D}(z) = \Phi^{-1}(P(D \le D_{raw} | \mathcal{P}_{ref}))
\end{equation}
where $\Phi^{-1}$ is the inverse cumulative distribution function of the standard normal distribution. 

\textbf{Assumption Clarification:} This process does \textit{not} assume that the underlying data or raw distances follow a Gaussian distribution. Instead, it employs non-parametric quantile mapping to \textit{force} the calibrated risk scores of the reference population to follow a standard normal distribution $\mathcal{N}(0, 1)$. This normalization allows us to define universal thresholds (e.g., $\hat{D} > 3.0$ implies a "3-sigma" rarity relative to the reference) regardless of the intrinsic geometry or modality of the embedding space.

\subsection{Control Policy}
The signals from ResLik, TCS, and MVA are aggregated to form a discrete control signal $\pi$. The policy enforces a conservative "circuit-breaker" logic:
\begin{itemize}
    \item If $\hat{D}(z) > \tau_{critical}$: Signal \texttt{ABSTAIN}.
    \item If $\tau_{warning} < \hat{D}(z) \le \tau_{critical}$: Signal \texttt{DOWNWEIGHT}.
    \item Otherwise: Signal \texttt{PROCEED}.
\end{itemize}
This deterministic policy ensures that the system's response to uncertainty is predictable and verifiable.
